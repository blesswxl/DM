{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from  sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_info = pd.read_csv('../data/app_info.csv',names=['appid','category'])\n",
    "user_app_actived = pd.read_csv('../data/user_app_actived.csv',names=['uid','appid'])\n",
    "user_basic_info = pd.read_csv('../data/user_basic_info.csv',names=['uid','gender','city','prodName','ramCapacity', 'ramLeftRation','romCapacity','romLeftRation','color', 'fontSize','ct','carrier','os'])\n",
    "user_basic_info.drop(columns=['city','prodName','color','ct','carrier'],inplace=True)\n",
    "age_test_data = pd.read_csv('../data/age_test.csv',names=['uid'])\n",
    "age_train_data = pd.read_csv('../data/age_train.csv',names=['uid','age_group'])\n",
    "age_test_data = pd.read_csv('../data/age_test.csv',names=['uid'])\n",
    "age_train_data = pd.read_csv('../data/age_train.csv',names=['uid','age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else:\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b/1024**2\n",
    "    return \"{:03.2f}MB\".format(usage_mb)\n",
    "\n",
    "\n",
    "def optimize_memory(df):\n",
    "    for col in ['appid','use_date']:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df['uid'] = df['uid'].astype('uint32')\n",
    "    for col in ['duration','times']:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    return df\n",
    "\n",
    "def get_use_eight_message(name,num):\n",
    "    data = pd.read_csv('../data/user_app_usage_feature_reset.csv')\n",
    "    data = data.sort_values(by=[name+'_mean'],ascending=False)\n",
    "    app = data.groupby(['uid'])['appid'].agg('#'.join)\n",
    "    app = app.reset_index()\n",
    "    data[name+'_mean'] = data[name+'_mean'].apply(lambda x:str(x))\n",
    "    app_mean_value = data.groupby(['uid'])[name+'_mean'].agg(' '.join)\n",
    "    app_mean_value = app_mean_value.reset_index()\n",
    "\n",
    "    data[name+'_max'] = data[name+'_max'].apply(lambda x:str(x))\n",
    "    app_max_value = data.groupby(['uid'])[name+'_max'].agg(' '.join)\n",
    "    app_max_value = app_max_value.reset_index()\n",
    "\n",
    "    data[name+'_min'] = data[name+'_min'].apply(lambda x:str(x))\n",
    "    app_min_value = data.groupby(['uid'])[name+'_min'].agg(' '.join)\n",
    "    app_min_value = app_min_value.reset_index()\n",
    "\n",
    "    del data\n",
    "    app['appidlist'] = app['appid'].apply(lambda x:x.split('#')[0:15])\n",
    "    app_mean_value[name+'_mean'] = app_mean_value[name+'_mean'].apply(lambda x:x.split(' ')[0:15])\n",
    "    app_max_value[name+'_max'] = app_max_value[name+'_max'].apply(lambda x:x.split(' ')[0:15])\n",
    "    app_min_value[name+'_min'] = app_min_value[name+'_min'].apply(lambda x:x.split(' ')[0:15])\n",
    "\n",
    "\n",
    "    for i in range(15):\n",
    "        app['appid'+str(i+num)] = app['appidlist'].apply(lambda x:x[i] if i<len(x) else np.nan)\n",
    "    app.drop(columns=['appidlist'],inplace=True)\n",
    "    for i in range(15):\n",
    "        app_mean_value['app_mean_value'+str(i+num)] = app_mean_value[name+'_mean'].apply(lambda x:float(x[i]) if i<len(x) else np.nan)\n",
    "    for i in range(15):\n",
    "        app_max_value['app_max_value'+str(i+num)] = app_max_value[name+'_max'].apply(lambda x:float(x[i]) if i<len(x) else np.nan)\n",
    "    for i in range(15):\n",
    "        app_min_value['app_min_value'+str(i+num)] = app_min_value[name+'_min'].apply(lambda x:float(x[i]) if i<len(x) else np.nan)\n",
    "    \n",
    "    app_mean_value.drop(columns=[name+'_mean'],inplace=True)\n",
    "    app_max_value.drop(columns=[name+'_max'],inplace=True)\n",
    "    app_min_value.drop(columns=[name+'_min'],inplace=True)\n",
    "    \n",
    "    app = app.merge(app_mean_value,on=['uid'],how='left')\n",
    "    app = app.merge(app_max_value,on=['uid'],how='left')\n",
    "    app = app.merge(app_min_value,on=['uid'],how='left')\n",
    "    app.to_csv('../feature/use_most_eight_{}_app.csv'.format(name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_cate_dict = {}\n",
    "appid_list = list(app_info['appid'].values)\n",
    "category_list = list(app_info['category'].values)\n",
    "for i in range(len(appid_list)):\n",
    "    if appid_list[i] in  app_cate_dict:\n",
    "        app_cate_dict[appid_list[i]].append(category_list[i])\n",
    "    else:\n",
    "        app_cate_dict[appid_list[i]] = []\n",
    "        app_cate_dict[appid_list[i]].append(category_list[i])\n",
    "user_app_num = {}\n",
    "for i in user_app_actived['appid'].values:\n",
    "    idlist = i.split('#')\n",
    "    for j in idlist:\n",
    "        if j in user_app_num:\n",
    "            user_app_num[j] = user_app_num[j]+1\n",
    "        else:\n",
    "            user_app_num[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_app_num2 = sorted(user_app_num.items(),key=lambda d:d[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_app_num_sort = {}\n",
    "for i,j in enumerate(user_app_num2):\n",
    "    user_app_num_sort[j[0]] = i+1\n",
    "print(user_app_num_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv('../data/user_app_usage.csv',iterator=True,names=['uid','appid','duration','times','use_date'])\n",
    "chunkSize = 10000000\n",
    "loop = True\n",
    "allchunk = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allchunk.drop(columns=['use_date'],axis=1,inplace=True)\n",
    "for col in allchunk.columns:\n",
    "    if col=='appid':\n",
    "        continue\n",
    "    _ = allchunk.groupby(['appid'],as_index=False)[col].agg({col+'_'+col.split('_')[-1]:col.split('_')[-1]})\n",
    "    allchunk = allchunk.merge(_,on=['appid'],how='left')\n",
    "    allchunk.drop(columns=[col],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allchunk = allchunk.drop_duplicates(['appid'])\n",
    "allchunk['number_sort'] = allchunk['appid'].apply(lambda x:user_app_num_sort[x] if x in user_app_num_sort else np.nan)\n",
    "allchunk['app_cate'] = allchunk['appid'].apply(lambda x:app_cate_dict[x][0] if x in app_cate_dict else 'unknow')\n",
    "allchunk.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allchunk.to_csv('../feature/app_feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = True\n",
    "allchunk = pd.DataFrame()\n",
    "while loop:\n",
    "    try:\n",
    "        chunk = reader.get_chunk(chunkSize)\n",
    "        chunk = optimize_memory(chunk)\n",
    "        chunk.drop(columns=['use_date'],axis=1,inplace=True)\n",
    "        chunk['duration_average'] = chunk['duration']/chunk['times']\n",
    "        print(len(chunk),mem_usage(chunk))\n",
    "\n",
    "        for col in ['duration','times','duration_average']:\n",
    "            _ = chunk.groupby(['uid','appid'],as_index=False)[col].agg({col+'_max':'max',col+'_min':'min',col+'_mean':'mean'})\n",
    "            chunk = chunk.merge(_,on=['uid','appid'],how='left')\n",
    "            chunk.drop(columns=[col],axis=1,inplace=True)\n",
    "\n",
    "        print(len(chunk))\n",
    "        chunk = chunk.drop_duplicates(['uid','appid'])\n",
    "        print(len(chunk))\n",
    "        allchunk = pd.concat([allchunk,chunk],ignore_index=True)\n",
    "        print(\"allchunk:\",len(allchunk),mem_usage(allchunk))\n",
    "    except StopIteration:\n",
    "        loop = False\n",
    "        print(\"Iteration is stopped\")\n",
    "\n",
    "for col in ['duration_max','duration_min','duration_mean','times_max','times_min','times_mean',\n",
    "            'duration_average_max','duration_average_min','duration_average_mean']:\n",
    "    _ = allchunk.groupby(['uid','appid'],as_index=False)[col].agg({col+'_'+col.split('_')[-1]:col.split('_')[-1]})\n",
    "    allchunk = allchunk.merge(_,on=['uid','appid'],how='left')\n",
    "    allchunk.drop(columns=[col],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "allchunk = allchunk.drop_duplicates(['uid','appid'])\n",
    "allchunk = allchunk.rename(columns={'duration_max_max':'duration_max','duration_min_min':'duration_min','duration_mean_mean':'duration_mean',\n",
    "                         'times_max_max':'times_max','times_min_min':'times_min','times_mean_mean':'times_mean',\n",
    "                        'duration_average_max_max':'duration_average_max','duration_average_min_min':'duration_average_min','duration_average_mean_mean':'duration_average_mean'\n",
    "                         })\n",
    "print(len(allchunk))\n",
    "\n",
    "allchunk.to_csv('../data/user_app_usage_feature_reset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_use_eight_message('duration',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_use_eight_message('times',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_dura = pd.read_csv('../feature/use_most_eight_duration_app.csv')\n",
    "app_feature = pd.read_csv('../feature/app_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_data = age_train_data.merge(most_dura,on=['uid'],how='left')\n",
    "age_test_data = age_test_data.merge(most_dura,on=['uid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in age_train_data.columns:\n",
    "    if 'appid' in i:\n",
    "        age_train_data.drop(columns=[i],inplace=True)\n",
    "        age_test_data.drop(columns=[i],inplace=True)\n",
    "    if 'value' in i:\n",
    "        age_train_data[i] = age_train_data[i].fillna(age_train_data[i].mean())\n",
    "        age_test_data[i] = age_test_data[i].fillna(age_train_data[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = [i for i in age_train_data.columns if 'value' in i]\n",
    "train_weight = age_train_data[value].values\n",
    "train_weight = train_weight.reshape(len(age_train_data),3,15).swapaxes(1,2)\n",
    "test_weight = age_test_data[value].values\n",
    "test_weight = test_weight.reshape(len(age_test_data),3,15).swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_weight.shape)\n",
    "print(test_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../feature/nn_weight_train.npy',train_weight)\n",
    "np.save('../feature/nn_weight_test.npy',test_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_app_actived['len'] = user_app_actived['appid_2'].apply(lambda x:len(x))\n",
    "print(len(user_app_actived))\n",
    "user_app_actived = user_app_actived[user_app_actived['len']>5]\n",
    "user_app_actived.drop(columns=['len'],inplace=True)\n",
    "print(len(user_app_actived))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_dura = most_dura[['uid','appid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_data = age_train_data.merge(most_dura,on=['uid'],how='left')\n",
    "age_train_data = age_train_data.merge(user_app_actived,on=['uid'],how='left')\n",
    "age_test_data = age_test_data.merge(most_dura,on=['uid'],how='left')\n",
    "age_test_data = age_test_data.merge(user_app_actived,on=['uid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_age = {}\n",
    "app_list = age_train_data['appid'].values\n",
    "app_age_list = age_train_data['age_group'].values\n",
    "for num,i in enumerate(app_age_list):\n",
    "    app = app_list[num]\n",
    "    if app is np.nan:\n",
    "        continue\n",
    "    if i in app_age:\n",
    "        for j in app.split('#'):\n",
    "            if j in app_age[i]:\n",
    "                app_age[i][j] = app_age[i][j]+1\n",
    "            else:\n",
    "                app_age[i][j] = 1\n",
    "    else:\n",
    "        for j in app.split('#'):\n",
    "            app_age[i] = {}\n",
    "            app_age[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_age_value = pd.DataFrame(app_age)\n",
    "app_age_value = app_age_value.reset_index().rename(columns={'index':'appid'})\n",
    "age_train_data['appid'] = age_train_data.apply(lambda x:x['appid'] if x['appid'] is not np.nan else x['appid_2'],axis=1)\n",
    "age_test_data['appid'] = age_test_data.apply(lambda x:x['appid'] if x['appid'] is not np.nan else x['appid_2'],axis=1) \n",
    "age_train_data.drop(columns=['appid_2'],inplace=True)\n",
    "age_test_data.drop(columns=['appid_2'],inplace=True)\n",
    "age_train_data['appid'] = age_train_data['appid'].fillna('a00289791#a0048467')\n",
    "age_test_data['appid'] = age_test_data['appid'].fillna('a00289791#a0048467')\n",
    "age_train_data['appid'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_feature = app_feature.merge(app_age_value,on='appid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_feature['allnum'] = app_feature[1]+app_feature[2]+app_feature[3]+app_feature[4]+app_feature[5]+app_feature[6]\n",
    "for i in [1,2,3,4,5,6]:\n",
    "    app_feature[i] = app_feature[i]/(app_feature['allnum']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6]:\n",
    "    app_feature[i] = app_feature[i].fillna(app_feature[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_feature['app_cate'] = app_feature['app_cate'].map(dict(zip(app_feature['app_cate'].unique(), range(0, app_feature['app_cate'].nunique()))))\n",
    "for i in app_feature.columns:\n",
    "    if i=='appid':\n",
    "        continue\n",
    "    app_feature[i] = app_feature[i].fillna(app_feature[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_dict = dict(zip(app_feature.values[:,0],app_feature.values[:,1:]))\n",
    "def get_app_feature_vec(a):\n",
    "    featurevec = np.zeros([15,39])\n",
    "    for num,i in enumerate(a.split('#')):\n",
    "        if num>=15:\n",
    "            break\n",
    "        featurevec[num,:] = app_dict[i]\n",
    "    return featurevec\n",
    "age_train_data['appid'] = age_train_data['appid'].apply(lambda x:get_app_feature_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test_data['appid'] = age_test_data['appid'].apply(lambda x:get_app_feature_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea = np.array(age_train_data['appid'].tolist())\n",
    "test_fea = np.array(age_test_data['appid'].tolist())\n",
    "np.save('../feature/nn_train.npy',train_fea)\n",
    "np.save('../feature/nn_test.npy',test_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('../feature/nn_train.npy')\n",
    "test = np.load('../feature/nn_test.npy')\n",
    "train_weight = np.load('../feature/nn_weight_train.npy')\n",
    "test_weight = np.load('../feature/nn_weight_test.npy')\n",
    "train_person = np.load('../feature/nn_person_train.npy')\n",
    "test_person = np.load('../feature/nn_person_test.npy')\n",
    "train_mat1 = np.load('../feature/nn_mat1_train.npy')\n",
    "test_mat1 = np.load('../feature/nn_mat1_test.npy')\n",
    "train_mat2 = np.load('../feature/nn_mat2_train.npy')\n",
    "test_mat2 = np.load('../feature/nn_mat2_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[0:100000]\n",
    "test = test[0:100000]\n",
    "train_weight = train_weight[0:100000]\n",
    "test_weight = test_weight[0:100000]\n",
    "train_person = train_person[0:100000]\n",
    "test_person = test_person[0:100000]\n",
    "train_mat1 = train_mat1[0:100000]\n",
    "test_mat1 = test_mat1[0:100000]\n",
    "train_mat2 = train_mat2[0:100000]\n",
    "test_mat2 = test_mat2[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = np.concatenate([train_mat1],1)\n",
    "test_mat = np.concatenate([test_mat1],1)\n",
    "del train_mat1\n",
    "del test_mat1\n",
    "train_person = np.concatenate([train_person,train_mat2],1)\n",
    "test_person = np.concatenate([test_person,test_mat2],1)\n",
    "del train_mat2\n",
    "del test_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight = train_weight.reshape(len(train),15,3)\n",
    "test_weight = test_weight.reshape(len(test),15,3)\n",
    "\n",
    "train_person = train_person.reshape(len(train),1,-1)\n",
    "test_person = test_person.reshape(len(test),1,-1)\n",
    "\n",
    "train_mat = train_mat.reshape(len(train),1,-1)\n",
    "test_mat = test_mat.reshape(len(test),1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_train_data = pd.read_csv('../data/age_train.csv',names=['uid','age_group'])\n",
    "age_train_data['age_group'] = age_train_data['age_group'].apply(lambda x:x-1)\n",
    "y_train = age_train_data['age_group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "from  sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for i in range(train.shape[2]):\n",
    "    scaler = preprocessing.StandardScaler().fit(train[:,:,i])\n",
    "    train[:,:,i] = scaler.transform(train[:,:,i]) \n",
    "    test[:,:,i] = scaler.transform(test[:,:,i])\n",
    "#     train[:,:,i] = min_max_scaler.fit_transform(train[:,:,i])\n",
    "#     test[:,:,i] = min_max_scaler.transform(test[:,:,i])\n",
    "for i in range(train_weight.shape[2]):\n",
    "    scaler = preprocessing.StandardScaler().fit(train_weight[:,:,i])\n",
    "    train_weight[:,:,i] = scaler.transform(train_weight[:,:,i]) \n",
    "    test_weight[:,:,i] = scaler.transform(test_weight[:,:,i])\n",
    "#     train_weight[:,:,i] = min_max_scaler.fit_transform(train_weight[:,:,i])\n",
    "#     test_weight[:,:,i] = min_max_scaler.transform(test_weight[:,:,i])\n",
    "for i in range(train_person.shape[2]):\n",
    "    scaler = preprocessing.StandardScaler().fit(train_person[:,:,i])\n",
    "    train_person[:,:,i] = scaler.transform(train_person[:,:,i]) \n",
    "    test_person[:,:,i] = scaler.transform(test_person[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "class Getdata(Dataset):\n",
    "    def __init__(self,feature,weight,person,mat1,labels,transform=preprocessing.normalize):\n",
    "        self.feature = feature\n",
    "        self.weight = weight\n",
    "        self.person = person\n",
    "        self.mat1 = mat1\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    def __getitem__(self, item):\n",
    "        sample={}\n",
    "        if self.labels is not None:\n",
    "            sample['label'] = self.labels[item]\n",
    "            sample['feature'] = self.transform(self.feature[item],norm='l2')\n",
    "            sample['weight'] = self.transform(self.weight[item],norm='l2')\n",
    "            sample['person'] = self.transform(self.person[item],norm='l2')\n",
    "            sample['mat1'] = self.mat1[item]\n",
    "        return sample\n",
    "\n",
    "class Gettestdata(Dataset):\n",
    "    def __init__(self,feature,weight,person,mat1,transform=preprocessing.normalize):\n",
    "        self.feature = feature\n",
    "        self.weight = weight\n",
    "        self.person = person\n",
    "        self.mat1 = mat1\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    def __getitem__(self, item):\n",
    "        sample={}\n",
    "        if self.feature is not None:\n",
    "            sample['feature'] = self.transform(self.feature[item],norm='l2')\n",
    "            sample['weight'] = self.transform(self.weight[item],norm='l2')\n",
    "            sample['person'] = self.transform(self.person[item],norm='l2')\n",
    "            sample['mat1'] = self.mat1[item]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self,hidden_dim1=600,hidden_dim2=100,hidden_dim3=6):\n",
    "        super(Mymodel,self).__init__()\n",
    "        self.mat1cnn = nn.Sequential(*[\n",
    "            nn.Conv2d(1,16,(1,3),stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,(1,3),stride=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,(1,5),stride=5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "        self.modelperson = nn.Sequential(*[\n",
    "            nn.Linear(1856, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "        ])\n",
    "        self.personcnn = nn.Sequential(*[\n",
    "            nn.Conv2d(1,16,(1,3),stride=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,(1,3),stride=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),    \n",
    "        ])\n",
    "        self.featurecnn = nn.Sequential(*[\n",
    "            nn.Conv2d(1,16,2,2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(1,1),\n",
    "            nn.Conv2d(16,32,3,3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(1,1),\n",
    "        ])\n",
    "    def forward(self,fea_weight,person,mat1):\n",
    "        fea_weight = fea_weight.float()\n",
    "        person = person.float()\n",
    "        person = person.unsqueeze(1)\n",
    "        mat1 = mat1.float()\n",
    "        mat1 = self.mat1cnn(mat1)\n",
    "        mat1 = mat1.view(mat1.shape[0],-1)\n",
    "        fea_weight = fea_weight.unsqueeze(1)\n",
    "        fea_weight = self.featurecnn(fea_weight)\n",
    "        fea_weight = fea_weight.view(fea_weight.shape[0],-1)\n",
    "        person = self.personcnn(person)\n",
    "        person = person.view(person.shape[0],-1)\n",
    "        allfeature = torch.cat((mat1,fea_weight,person),1)\n",
    "        end = self.modelperson(allfeature)\n",
    "        return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, y_train)):\n",
    "    print(fold_)\n",
    "    if fold_==1:\n",
    "        break\n",
    "    model = Mymodel()\n",
    "    model = model.to(device)\n",
    "    train_loaders = DataLoader(Getdata(train[trn_idx],train_weight[trn_idx],\n",
    "                                       train_person[trn_idx],train_mat[trn_idx],y_train[trn_idx]),batch_size=64,shuffle=True)\n",
    "    val_loaders = DataLoader(Getdata(train[val_idx],train_weight[val_idx],\n",
    "                                      train_person[val_idx],train_mat[val_idx],y_train[val_idx]),batch_size=64,shuffle=True)\n",
    "    test_loaders = DataLoader(Gettestdata(test,test_weight,test_person,test_mat),batch_size=64)\n",
    "    n_ep = 4\n",
    "    wd = 1e-5\n",
    "    lr = 1e-4\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=wd, lr=lr)\n",
    "    for i_ep in range(n_ep):\n",
    "        for _,sample in tqdm(enumerate(train_loaders),total=len(train_loaders)):\n",
    "            feature = sample['feature'].to(device)\n",
    "            weight = sample['weight'].to(device)\n",
    "            fea_weight = torch.cat((feature,weight),2)\n",
    "            person = sample['person'].to(device)\n",
    "            mat1 = sample['mat1'].to(device)\n",
    "            mat1 = mat1.unsqueeze(1)\n",
    "            label = sample['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            result = model.forward(fea_weight,person,mat1)\n",
    "            loss = criterion(result,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            valmodel = model.eval()\n",
    "            losses = []\n",
    "            labels = []\n",
    "            preds = []\n",
    "            for _,sample_val in enumerate(val_loaders):\n",
    "                feature_val = sample_val['feature'].to(device)\n",
    "                weight_val = sample_val['weight'].to(device)\n",
    "                fea_weight_val = torch.cat((feature_val,weight_val),2)\n",
    "                person_val = sample_val['person'].to(device)\n",
    "                mat1_val = sample_val['mat1'].to(device)\n",
    "                mat1_val = mat1_val.unsqueeze(1)\n",
    "                label_val = sample_val['label'].to(device)\n",
    "                result_val = valmodel.forward(fea_weight_val,person_val,mat1_val)\n",
    "                preds += [np.argmax(result_val.detach().cpu().numpy(),axis=1)]\n",
    "                labels += [label_val.detach().cpu().numpy()]\n",
    "            preds = np.concatenate(preds, 0)\n",
    "            labels = np.concatenate(labels, 0)\n",
    "            print(accuracy_score(labels,preds))\n",
    "    with torch.no_grad():\n",
    "        testmodel = model.eval()\n",
    "        preds_test = []\n",
    "        for _,sample_test in tqdm(enumerate(test_loaders),total=len(test_loaders)):\n",
    "            feature_test = sample_test['feature'].to(device)\n",
    "            weight_test = sample_test['weight'].to(device)\n",
    "            fea_weight_test = torch.cat((feature_test,weight_test),2)\n",
    "            person_test = sample_test['person'].to(device)\n",
    "            mat1_test = sample_test['mat1'].to(device)\n",
    "            mat1_test = mat1_test.unsqueeze(1)\n",
    "            result_test = testmodel.forward(fea_weight_test,person_test,mat1_test)\n",
    "            preds_test += [np.argmax(result_test.detach().cpu().numpy(),axis=1)]\n",
    "        np = np.concatenate(preds_test, 0)\n",
    "        print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test_data = pd.read_csv('../data/age_test.csv',names=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test_data['label'] = predictions\n",
    "age_test_data['label'] = age_test_data['label'].apply(lambda x:round(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test_data[['id','label']].to_csv('../submit/submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
